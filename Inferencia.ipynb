{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7f21ebc",
   "metadata": {},
   "source": [
    "\n",
    "# Inferencia — Predicción de Consumo, Precio y Utilidad (sin gráficos)\n",
    "\n",
    "Este cuaderno:\n",
    "- Construye *features* (rezagos, medias móviles, dummies).\n",
    "- Hace **partición temporal** (train/val/test) por año sin *leakage*.\n",
    "- Entrena **baselines** y modelos (Ridge/Lasso/RandomForest; intenta LightGBM/XGBoost si están disponibles).\n",
    "- Calcula métricas: **MAE, RMSE, MAPE, sMAPE, R²**.\n",
    "- Guarda modelos `.joblib` y predicciones como CSV con columnas `country, type, year, target, y_true, y_pred, residual, model`.\n",
    "- Resume resultados en texto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ae8287d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompose\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "import warnings, json\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "\n",
    "from utils.metrics import mae, rmse, r2, mape, smape, regression_report\n",
    "\n",
    "DATA_CLEAN = \"data/coffee_clean.csv\"\n",
    "MODELS_DIR = \"models\"\n",
    "PRED_DIR = \"predicciones\"\n",
    "Path(MODELS_DIR).mkdir(exist_ok=True)\n",
    "Path(PRED_DIR).mkdir(exist_ok=True)\n",
    "\n",
    "TARGETS = {\n",
    "    \"consumption\": \"consumption\",\n",
    "    \"price\": \"price\",\n",
    "    \"profit\": \"profit\",\n",
    "}\n",
    "\n",
    "TEST_END = 2020\n",
    "VAL_YEARS = 3\n",
    "TEST_YEARS = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc18baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Carga de datos\n",
    "df = pd.read_csv(DATA_CLEAN)\n",
    "df = df.sort_values([\"country\", \"type\", \"year\"]).reset_index(drop=True)\n",
    "\n",
    "FEATURE_BASE = [\"country\", \"type\", \"year\"]\n",
    "assert all(c in df.columns for c in FEATURE_BASE+[\"consumption\",\"price\",\"profit\"]), \"Faltan columnas requeridas\"\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2049cad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Feature engineering\n",
    "def add_lags_and_ma(g, cols, lags=(1,2,3), mas=(2,3)):\n",
    "    g = g.copy()\n",
    "    for col in cols:\n",
    "        for L in lags:\n",
    "            g[f\"{col}_lag{L}\"] = g[col].shift(L)\n",
    "        for M in mas:\n",
    "            g[f\"{col}_ma{M}\"] = g[col].rolling(M).mean()\n",
    "    return g\n",
    "\n",
    "def build_features(df):\n",
    "    parts = []\n",
    "    for keys, g in df.groupby([\"country\",\"type\"], as_index=False):\n",
    "        g2 = add_lags_and_ma(g, cols=[\"consumption\",\"price\",\"profit\"])\n",
    "        parts.append(g2)\n",
    "    X = pd.concat(parts).sort_values([\"country\",\"type\",\"year\"]).reset_index(drop=True)\n",
    "    return X\n",
    "\n",
    "X = build_features(df)\n",
    "X_ffill = X.groupby([\"country\",\"type\"], group_keys=False).apply(lambda g: g.ffill())\n",
    "X = X_ffill\n",
    "X.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902194fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Partición temporal sin leakage\n",
    "min_year, max_year = int(X[\"year\"].min()), int(X[\"year\"].max())\n",
    "test_start = max_year - TEST_YEARS + 1\n",
    "val_end = test_start - 1\n",
    "val_start = val_end - VAL_YEARS + 1\n",
    "train_end = val_start - 1\n",
    "\n",
    "splits = {\n",
    "    \"train\": (min_year, train_end),\n",
    "    \"val\": (val_start, val_end),\n",
    "    \"test\": (test_start, max_year),\n",
    "}\n",
    "splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcab00ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Baselines por grupo (país-tipo): último valor y promedio histórico\n",
    "from utils.metrics import mae, rmse, r2, mape, smape\n",
    "\n",
    "def baseline_last(g, target):\n",
    "    return g[target].shift(1)\n",
    "\n",
    "def baseline_mean(g, target):\n",
    "    return g[target].shift(1).expanding().mean()\n",
    "\n",
    "def compute_baselines(X, target):\n",
    "    Xb = X.copy()\n",
    "    Xb[\"y_true\"] = Xb[target]\n",
    "    Xb[\"y_last\"] = Xb.groupby([\"country\",\"type\"], group_keys=False).apply(lambda g: baseline_last(g, target))\n",
    "    Xb[\"y_mean\"] = Xb.groupby([\"country\",\"type\"], group_keys=False).apply(lambda g: baseline_mean(g, target))\n",
    "    return Xb\n",
    "\n",
    "def evaluate_series(y_true, y_pred):\n",
    "    return {\n",
    "        \"MAE\": mae(y_true, y_pred),\n",
    "        \"RMSE\": rmse(y_true, y_pred),\n",
    "        \"MAPE\": mape(y_true, y_pred),\n",
    "        \"sMAPE\": smape(y_true, y_pred),\n",
    "        \"R2\": r2(y_true, y_pred),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f748e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Modelos supervisados\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def build_preprocessor():\n",
    "    cat_features = [\"country\",\"type\"]\n",
    "    num_features = [c for c in X.columns if c not in [\"country\",\"type\",\"year\",\"consumption\",\"price\",\"profit\"]]\n",
    "    pre = ColumnTransformer([\n",
    "        (\"cats\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_features),\n",
    "        (\"nums\", \"passthrough\", num_features),\n",
    "    ])\n",
    "    return pre, num_features\n",
    "\n",
    "def train_and_eval_model(X, target, model, model_name):\n",
    "    pre, num_features = build_preprocessor()\n",
    "    y = X[target]\n",
    "    feats = [c for c in X.columns if c not in [\"consumption\",\"price\",\"profit\"]]\n",
    "    pipe = Pipeline([(\"pre\", pre), (\"model\", model)])\n",
    "    def mask_year(a, b): return (X[\"year\"] >= a) & (X[\"year\"] <= b)\n",
    "    train_mask = mask_year(*splits[\"train\"])\n",
    "    val_mask = mask_year(*splits[\"val\"])\n",
    "    test_mask = mask_year(*splits[\"test\"])\n",
    "\n",
    "    pipe.fit(X.loc[train_mask | val_mask, feats], y.loc[train_mask | val_mask])\n",
    "    pred_test = pipe.predict(X.loc[test_mask, feats])\n",
    "\n",
    "    report = evaluate_series(y.loc[test_mask], pred_test)\n",
    "    out_path = Path(MODELS_DIR) / f\"{model_name}_{target}.joblib\"\n",
    "    import joblib\n",
    "    joblib.dump(pipe, out_path)\n",
    "    pred_df = (X.loc[test_mask, [\"country\",\"type\",\"year\"]].copy()\n",
    "                 .assign(target=target, y_true=y.loc[test_mask].values, y_pred=pred_test))\n",
    "    pred_df[\"residual\"] = pred_df[\"y_true\"] - pred_df[\"y_pred\"]\n",
    "    pred_df[\"model\"] = model_name\n",
    "    return report, out_path, pred_df\n",
    "\n",
    "MODELS = {\n",
    "    \"ridge\": Ridge(alpha=1.0, random_state=42),\n",
    "    \"lasso\": Lasso(alpha=0.001, random_state=42, max_iter=10000),\n",
    "    \"rf\": RandomForestRegressor(n_estimators=400, random_state=42, n_jobs=-1),\n",
    "}\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb  # type: ignore\n",
    "    MODELS[\"lgbm\"] = lgb.LGBMRegressor(random_state=42, n_estimators=500)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb  # type: ignore\n",
    "    MODELS[\"xgb\"] = xgb.XGBRegressor(random_state=42, n_estimators=500, max_depth=6, subsample=0.8, colsample_bytree=0.8)\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844df69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Entrenamiento/evaluación por target\n",
    "all_results = []\n",
    "all_predictions = []\n",
    "\n",
    "def eval_baselines_on_test(X, target):\n",
    "    Xb = compute_baselines(X, target)\n",
    "    a, b = splits[\"test\"]\n",
    "    mask = (Xb[\"year\"] >= a) & (Xb[\"year\"] <= b)\n",
    "    base_last = evaluate_series(Xb.loc[mask,\"y_true\"], Xb.loc[mask,\"y_last\"])\n",
    "    base_mean = evaluate_series(Xb.loc[mask,\"y_true\"], Xb.loc[mask,\"y_mean\"])\n",
    "    return base_last, base_mean\n",
    "\n",
    "baseline_summary = {}\n",
    "\n",
    "for target in [\"consumption\",\"price\",\"profit\"]:\n",
    "    base_last, base_mean = eval_baselines_on_test(X, target)\n",
    "    baseline_summary[target] = {\"baseline_last\": base_last, \"baseline_mean\": base_mean}\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "results_rows = []\n",
    "preds_parts = []\n",
    "\n",
    "for target in [\"consumption\",\"price\",\"profit\"]:\n",
    "    for name, model in MODELS.items():\n",
    "        report, model_path, pred_df = train_and_eval_model(X, target, model, name)\n",
    "        row = {\"target\": target, \"model\": name, **report}\n",
    "        results_rows.append(row)\n",
    "        preds_parts.append(pred_df)\n",
    "\n",
    "results_df = pd.DataFrame(results_rows).sort_values([\"target\",\"RMSE\"])\n",
    "preds_df = pd.concat(preds_parts, ignore_index=True)\n",
    "\n",
    "pred_file = Path(PRED_DIR) / \"predicciones_test.csv\"\n",
    "preds_df.to_csv(pred_file, index=False)\n",
    "\n",
    "results_df.head(10), pred_file, baseline_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4a4e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Resumen ejecutivo (texto)\n",
    "def best_model_text(results_df):\n",
    "    lines = []\n",
    "    for t, g in results_df.groupby(\"target\"):\n",
    "        g2 = g.sort_values(\"RMSE\").iloc[0]\n",
    "        lines.append(f\"- **{t}**: mejor modelo = {g2['model']} (RMSE={g2['RMSE']:.2f}, MAE={g2['MAE']:.2f}, sMAPE={g2['sMAPE']:.2f}%).\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "summary = \"\\n\".join([\n",
    "    \"## Conclusiones\",\n",
    "    f\"Rango temporal de entrenamiento/validación y prueba: {splits}.\",\n",
    "    \"\",\n",
    "    \"### Desempeño por objetivo\",\n",
    "    best_model_text(results_df),\n",
    "    \"\",\n",
    "    \"- Los baselines (`último valor` y `promedio histórico`) sirven de referencia; en general los modelos supervisados los superan según RMSE/MAE.\",\n",
    "    \"- La **predicción de consumo** suele beneficiarse de rezagos y medias móviles.\",\n",
    "    \"- La **predicción de precio** al usar un precio global anualizado es más volátil; los modelos de bosque/boosting suelen capturar mejor no-linealidades.\",\n",
    "    \"- La **utilidad** depende de supuestos de costos; los resultados deben revisarse con finanzas para ajustar `FIXED_COST` y `VAR_COST_PER_CUP`.\",\n",
    "    \"\",\n",
    "    \"Los modelos y las predicciones de test se han guardado en:\",\n",
    "    f\"- Carpeta de modelos: {MODELS_DIR}/\",\n",
    "    f\"- Archivo de predicciones: {PRED_DIR}/predicciones_test.csv\",\n",
    "])\n",
    "\n",
    "print(summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
