{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c50bd35",
   "metadata": {},
   "source": [
    "\n",
    "# üìò High Garden Coffee ‚Äî **Evaluaci√≥n (Holdout)**\n",
    "\n",
    "Este notebook carga **predicciones** existentes (si las hay) o construye **baselines** y genera un **Resumen Ejecutivo** con m√©tricas, tablas √∫tiles y archivos de salida listos para presentar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e954626",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Setup b√°sico (sin dependencias nuevas) ===\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import json, math, glob, textwrap\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:,.6f}\")\n",
    "print(\"‚úÖ Entorno listo ‚Äî pandas:\", pd.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831cc2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Configuraci√≥n ===\n",
    "# Cambia el TARGET si quieres evaluar otro objetivo: 'price' | 'consumption' | 'profit'\n",
    "TARGET = \"price\"  # <-- puedes cambiar aqu√≠\n",
    "# Si conoces el holdout expl√≠cito, ponlo aqu√≠; si no, el notebook lo detecta.\n",
    "HOLDOUT_YEAR = None  # p.ej., 2020\n",
    "\n",
    "# Rutas t√≠picas del repo\n",
    "DIR_PRED = Path(\"predicciones\")\n",
    "DIR_RES  = Path(\"results\")\n",
    "DIR_DATA = Path(\"data\")\n",
    "DIR_MODELS = Path(\"models\")\n",
    "\n",
    "DIR_RES.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"TARGET:\", TARGET)\n",
    "print(\"HOLDOUT_YEAR:\", HOLDOUT_YEAR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b29110",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Utilidades ===\n",
    "def print_header(title: str):\n",
    "    bar = \"‚Äî\"*112\n",
    "    print(bar)\n",
    "    print(title.upper())\n",
    "    print(bar)\n",
    "\n",
    "def read_csv_safe(path: Path) -> pd.DataFrame | None:\n",
    "    try:\n",
    "        if path.exists():\n",
    "            return pd.read_csv(path)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] No pude leer {path}: {e}\")\n",
    "    return None\n",
    "\n",
    "def format_metrics(m: dict) -> str:\n",
    "    keys = [\"RMSE\", \"MAE\", \"sMAPE(%)\", \"R2\", \"n_val\", \"year_val\"]\n",
    "    out = []\n",
    "    for k in keys:\n",
    "        v = m.get(k, None)\n",
    "        if isinstance(v, float):\n",
    "            if \"sMAPE\" in k:\n",
    "                out.append(f\"{k:<10}: {v:,.4f}\")\n",
    "            else:\n",
    "                out.append(f\"{k:<10}: {v:,.6f}\")\n",
    "        elif v is None:\n",
    "            continue\n",
    "        else:\n",
    "            out.append(f\"{k:<10}: {v}\")\n",
    "    return \"\\n\".join(out)\n",
    "\n",
    "def mae(y, yhat): \n",
    "    y, yhat = np.asarray(y, float), np.asarray(yhat, float)\n",
    "    return float(np.mean(np.abs(y - yhat)))\n",
    "\n",
    "def rmse(y, yhat):\n",
    "    y, yhat = np.asarray(y, float), np.asarray(yhat, float)\n",
    "    return float(math.sqrt(np.mean((y - yhat)**2)))\n",
    "\n",
    "def smape(y, yhat):\n",
    "    y, yhat = np.asarray(y, float), np.asarray(yhat, float)\n",
    "    denom = (np.abs(y) + np.abs(yhat))\n",
    "    return float(np.mean(np.where(denom == 0, 0.0, 2.0*np.abs(y - yhat)/(denom+1e-12))) * 100)\n",
    "\n",
    "def r2(y, yhat):\n",
    "    y, yhat = np.asarray(y, float), np.asarray(yhat, float)\n",
    "    ss_res = np.sum((y - yhat)**2)\n",
    "    ss_tot = np.sum((y - np.mean(y))**2)\n",
    "    return float(1 - ss_res/(ss_tot + 1e-12))\n",
    "\n",
    "def detect_columns(df: pd.DataFrame, target: str):\n",
    "    # intenta detectar y_true y y_pred en un DF\n",
    "    y_true_cands = [c for c in df.columns if c in [\"y_true\", target]]\n",
    "    y_pred_cands = [c for c in df.columns if c in [\"y_pred\", f\"pred_{target}\"]]\n",
    "    y_true = y_true_cands[0] if y_true_cands else None\n",
    "    y_pred = y_pred_cands[0] if y_pred_cands else None\n",
    "    return y_true, y_pred\n",
    "\n",
    "def load_master_df():\n",
    "    # orden de preferencia\n",
    "    for cand in [DIR_DATA/\"coffee_clean.csv\", Path(\"coffee_clean.csv\"), Path(\"coffee_db.csv\")]:\n",
    "        dfm = read_csv_safe(cand)\n",
    "        if dfm is not None:\n",
    "            return dfm\n",
    "    return None\n",
    "\n",
    "def pick_latest(paths: list[str]) -> Path | None:\n",
    "    paths = [Path(p) for p in paths if Path(p).exists()]\n",
    "    if not paths:\n",
    "        return None\n",
    "    paths.sort(key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    return paths[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9ddd83",
   "metadata": {},
   "source": [
    "## 1) Carga de predicciones (si existen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568b325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_header(\"B√∫squeda de archivos de predicci√≥n\")\n",
    "candidates = []\n",
    "candidates += glob.glob(str(DIR_PRED / f\"pred_{TARGET}*.csv\"))\n",
    "candidates += glob.glob(str(DIR_RES  / f\"preds_{TARGET}.csv\"))\n",
    "cand = pick_latest(candidates)\n",
    "\n",
    "if cand is None:\n",
    "    print(\"No encontr√© archivos de predicci√≥n en predicciones/ ni results/.\")\n",
    "    PRED_PATH = None\n",
    "    df_pred = None\n",
    "else:\n",
    "    PRED_PATH = Path(cand)\n",
    "    print(\"Usando predicciones:\", PRED_PATH)\n",
    "    df_pred = read_csv_safe(PRED_PATH)\n",
    "\n",
    "if df_pred is not None:\n",
    "    print(\"Shape:\", df_pred.shape)\n",
    "    display(df_pred.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb926e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_header(\"Validaci√≥n y enriquecimiento de predicciones\")\n",
    "y_true_col, y_pred_col = (None, None)\n",
    "if df_pred is not None:\n",
    "    y_true_col, y_pred_col = detect_columns(df_pred, TARGET)\n",
    "    if y_true_col and y_pred_col:\n",
    "        print(\"Columnas detectadas:\", y_true_col, \"|\", y_pred_col)\n",
    "    else:\n",
    "        print(\"No encontr√© columnas de y_true/y_pred directamente. Intentar√© reconstruir y_true desde data maestra‚Ä¶\")\n",
    "        # Intentar merge con master\n",
    "        master = load_master_df()\n",
    "        if master is not None and TARGET in master.columns:\n",
    "            # claves comunes\n",
    "            keys = [k for k in [\"year\",\"country\",\"type\"] if k in df_pred.columns and k in master.columns]\n",
    "            if keys:\n",
    "                df_pred = df_pred.merge(master[keys+[TARGET]], on=keys, how=\"left\")\n",
    "                y_true_col = TARGET\n",
    "                if f\"pred_{TARGET}\" in df_pred.columns:\n",
    "                    y_pred_col = f\"pred_{TARGET}\"\n",
    "                elif \"y_pred\" in df_pred.columns:\n",
    "                    y_pred_col = \"y_pred\"\n",
    "                print(\"Reconstruidas columnas:\", y_true_col, \"|\", y_pred_col, \" (v√≠a merge)\")\n",
    "            else:\n",
    "                print(\"[WARN] No hay claves comunes para merge. No se pudo reconstruir y_true.\")\n",
    "        else:\n",
    "            print(\"[WARN] No se pudo cargar data maestra o no contiene el target.\")\n",
    "\n",
    "# Filtro y limpieza final\n",
    "if df_pred is not None and y_true_col and y_pred_col:\n",
    "    cols_keep = [c for c in [y_true_col, y_pred_col, \"year\", \"country\", \"type\"] if c in df_pred.columns]\n",
    "    df_eval = df_pred[cols_keep].copy()\n",
    "    df_eval = df_eval.dropna()\n",
    "    if df_eval.empty:\n",
    "        print(\"[WARN] No hay filas evaluables tras dropna().\")\n",
    "    else:\n",
    "        display(df_eval.head(5))\n",
    "else:\n",
    "    df_eval = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe971c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_header(\"M√©tricas globales del modelo (si hay predicciones)\")\n",
    "metrics_model = None\n",
    "if df_eval is not None and not df_eval.empty:\n",
    "    y = df_eval[y_true_col].astype(float).to_numpy()\n",
    "    yhat = df_eval[y_pred_col].astype(float).to_numpy()\n",
    "    metrics_model = {\n",
    "        \"RMSE\": rmse(y, yhat),\n",
    "        \"MAE\": mae(y, yhat),\n",
    "        \"sMAPE(%)\": smape(y, yhat),\n",
    "        \"R2\": r2(y, yhat),\n",
    "        \"n_val\": int(len(df_eval)),\n",
    "    }\n",
    "    # detectar holdout year si no viene seteado\n",
    "    if HOLDOUT_YEAR is None and \"year\" in df_eval.columns:\n",
    "        years = sorted(df_eval[\"year\"].dropna().unique().tolist())\n",
    "        HOLDOUT_YEAR = int(years[-1]) if years else None\n",
    "    if HOLDOUT_YEAR is not None:\n",
    "        metrics_model[\"year_val\"] = HOLDOUT_YEAR\n",
    "    \n",
    "    print(format_metrics(metrics_model))\n",
    "else:\n",
    "    print(\"No hay predicciones evaluables. Continuar√© con baselines y/o preparar√© plantilla de evaluaci√≥n.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9cd684",
   "metadata": {},
   "source": [
    "## 2) Comparaci√≥n contra **baselines** (si hay data maestra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929012a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_header(\"Construcci√≥n y evaluaci√≥n de baselines\")\n",
    "baseline_metrics = {}\n",
    "df_baselines_view = None\n",
    "\n",
    "master = load_master_df()\n",
    "if master is None or TARGET not in (master.columns if master is not None else []):\n",
    "    print(\"No pude cargar data maestra o no contiene la columna target. Saltando baselines.\")\n",
    "else:\n",
    "    # normalizar tipos\n",
    "    if \"year\" in master.columns:\n",
    "        master[\"year\"] = pd.to_numeric(master[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    # seleccionar holdout\n",
    "    if HOLDOUT_YEAR is None and df_eval is not None and \"year\" in df_eval.columns and not df_eval.empty:\n",
    "        years = sorted(df_eval[\"year\"].dropna().unique().tolist())\n",
    "        HOLDOUT_YEAR = int(years[-1]) if years else None\n",
    "        print(\"Detect√© HOLDOUT_YEAR:\", HOLDOUT_YEAR)\n",
    "    elif HOLDOUT_YEAR is None:\n",
    "        # fallback: √∫ltimo a√±o en master\n",
    "        years_m = sorted(master[\"year\"].dropna().unique().tolist()) if \"year\" in master.columns else []\n",
    "        HOLDOUT_YEAR = int(years_m[-1]) if years_m else None\n",
    "        print(\"Usar√© HOLDOUT_YEAR (fallback):\", HOLDOUT_YEAR)\n",
    "\n",
    "    if HOLDOUT_YEAR is None:\n",
    "        print(\"[WARN] No se pudo determinar el a√±o de holdout. No puedo crear baselines temporales.\")\n",
    "    else:\n",
    "        # Filtrar hist√≥rico y holdout\n",
    "        keys = [k for k in [\"country\",\"type\"] if k in master.columns]\n",
    "        hist = master[master[\"year\"] < HOLDOUT_YEAR].copy()\n",
    "        test = master[master[\"year\"] == HOLDOUT_YEAR].copy()\n",
    "        if not keys:\n",
    "            # si no hay llaves de grupo, trabajamos a nivel total\n",
    "            hist[\"_grp\"] = \"all\"\n",
    "            test[\"_grp\"] = \"all\"\n",
    "            keys = [\"_grp\"]\n",
    "\n",
    "        # Baseline 1: √öltimo valor por grupo (LOCF)\n",
    "        last_hist = hist.sort_values(\"year\").groupby(keys)[TARGET].last().rename(\"yhat_last\").reset_index()\n",
    "        base_last = test.merge(last_hist, on=keys, how=\"left\")\n",
    "\n",
    "        # Baseline 2: Promedio hist√≥rico por grupo\n",
    "        mean_hist = hist.groupby(keys)[TARGET].mean().rename(\"yhat_mean\").reset_index()\n",
    "        base_mean = test.merge(mean_hist, on=keys, how=\"left\")\n",
    "\n",
    "        # Si tenemos df_eval con y_true/y_pred, nos alineamos a sus llaves para comparaci√≥n justa\n",
    "        align_keys = [k for k in [\"year\"]+keys if df_eval is not None and k in df_eval.columns]\n",
    "        if df_eval is not None and align_keys:\n",
    "            gold = df_eval.rename(columns={y_true_col:\"y_true\"})[align_keys+[\"y_true\"]].drop_duplicates()\n",
    "        else:\n",
    "            gold = test[[\"year\"]+keys+[TARGET]].rename(columns={TARGET:\"y_true\"})\n",
    "\n",
    "        dfb = gold.merge(base_last, on=[\"year\"]+keys, how=\"left\").merge(base_mean, on=[\"year\"]+keys, how=\"left\")\n",
    "        # M√©tricas\n",
    "        def met(df, col):\n",
    "            ok = df[[\"y_true\", col]].dropna()\n",
    "            if ok.empty: return None\n",
    "            return {\n",
    "                \"RMSE\": rmse(ok[\"y_true\"], ok[col]),\n",
    "                \"MAE\": mae(ok[\"y_true\"], ok[col]),\n",
    "                \"sMAPE(%)\": smape(ok[\"y_true\"], ok[col]),\n",
    "                \"n_val\": int(len(ok)),\n",
    "                \"year_val\": int(HOLDOUT_YEAR),\n",
    "            }\n",
    "        m_last = met(dfb, \"yhat_last\")\n",
    "        m_mean = met(dfb, \"yhat_mean\")\n",
    "        if m_last: \n",
    "            baseline_metrics[\"last_value\"] = m_last\n",
    "            print(\"Baseline ‚Äî √∫ltimo valor:\n",
    "\" + format_metrics(m_last))\n",
    "        if m_mean:\n",
    "            baseline_metrics[\"mean_hist\"] = m_mean\n",
    "            print(\"\\nBaseline ‚Äî promedio hist√≥rico:\n",
    "\" + format_metrics(m_mean))\n",
    "\n",
    "        # vista tabular\n",
    "        show_cols = [c for c in [\"year\"]+keys+[\"y_true\",\"yhat_last\",\"yhat_mean\"] if c in dfb.columns]\n",
    "        df_baselines_view = dfb[show_cols].head(20)\n",
    "        if not df_baselines_view.empty:\n",
    "            print(\"\\nMuestra de baselines (primeras 20 filas):\")\n",
    "            display(df_baselines_view)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ca4254",
   "metadata": {},
   "source": [
    "## 3) An√°lisis de errores del modelo (si hay predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9898a13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_header(\"Ranking de errores por observaci√≥n y por pa√≠s/tipo\")\n",
    "df_errors_rank = None\n",
    "if df_eval is not None and not df_eval.empty:\n",
    "    dfm = df_eval.copy()\n",
    "    dfm[\"abs_err\"] = (dfm[y_true_col] - dfm[y_pred_col]).abs()\n",
    "    dfm[\"pct_err\"] = np.where(dfm[y_true_col]!=0, dfm[\"abs_err\"]/dfm[y_true_col]*100, np.nan)\n",
    "\n",
    "    # Top 10 peores / mejores (por error absoluto)\n",
    "    worst10 = dfm.sort_values(\"abs_err\", ascending=False).head(10)\n",
    "    best10  = dfm.sort_values(\"abs_err\", ascending=True).head(10)\n",
    "\n",
    "    print(\"üî¥ Peores 10 (mayor error absoluto):\")\n",
    "    display(worst10)\n",
    "    print(\"\\nüü¢ Mejores 10 (menor error absoluto):\")\n",
    "    display(best10)\n",
    "\n",
    "    # Agregados por pa√≠s y tipo (si existen)\n",
    "    keys = [k for k in [\"country\",\"type\"] if k in dfm.columns]\n",
    "    if keys:\n",
    "        agg = dfm.groupby(keys).agg(\n",
    "            n=(\"abs_err\",\"count\"),\n",
    "            MAE=(\"abs_err\",\"mean\"),\n",
    "            RMSE=(\"abs_err\", lambda s: float(math.sqrt(np.mean(s**2)))),\n",
    "            sMAPE=(\"pct_err\",\"mean\")\n",
    "        ).reset_index().sort_values(\"MAE\", ascending=True)\n",
    "        print(\"\\nResumen por grupo (ordenado por MAE ascendente):\")\n",
    "        display(agg.head(20))\n",
    "        df_errors_rank = agg\n",
    "else:\n",
    "    print(\"No hay predicciones para analizar errores.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94658ed",
   "metadata": {},
   "source": [
    "## 4) Resumen Ejecutivo + Exportables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e2c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_header(\"RESUMEN EJECUTIVO DE EVALUACI√ìN\")\n",
    "\n",
    "ev = {\n",
    "    \"target\": TARGET,\n",
    "    \"metrics\": {},\n",
    "    \"best_artifact\": None,\n",
    "    \"generated_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "}\n",
    "\n",
    "# Seleccionar mejor artefacto (heur√≠stica por nombre)\n",
    "arts = sorted(glob.glob(str(DIR_MODELS / f\"*{TARGET}*.joblib\")))\n",
    "ev[\"best_artifact\"] = arts[-1] if arts else \"desconocido\"\n",
    "\n",
    "# M√©tricas del modelo (si existen)\n",
    "if metrics_model:\n",
    "    ev[\"metrics\"].update(metrics_model)\n",
    "\n",
    "# Si existen baselines, agregar para comparaci√≥n\n",
    "if baseline_metrics:\n",
    "    ev[\"metrics_baselines\"] = baseline_metrics\n",
    "\n",
    "# Guardar JSON\n",
    "out_json = DIR_RES / f\"ev_{TARGET}.json\"\n",
    "out_json.write_text(json.dumps(ev, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "print(\"üíæ Guardado:\", out_json)\n",
    "\n",
    "# Mostrar resumen legible\n",
    "if metrics_model:\n",
    "    print(\"\\nModelo (predicciones):\\n\" + format_metrics(metrics_model))\n",
    "if baseline_metrics:\n",
    "    for name, met in baseline_metrics.items():\n",
    "        print(f\"\\nBaseline ‚Äî {name}:\\n\" + format_metrics(met))\n",
    "\n",
    "# Guardar tablas auxiliares si existen\n",
    "if 'df_baselines_view' in globals() and df_baselines_view is not None:\n",
    "    p = DIR_RES / f\"baseline_view_{TARGET}.csv\"\n",
    "    df_baselines_view.to_csv(p, index=False)\n",
    "    print(\"üíæ Guardado:\", p)\n",
    "\n",
    "if 'df_eval' in globals() and df_eval is not None and not df_eval.empty:\n",
    "    tmp = df_eval.copy()\n",
    "    if \"abs_err\" not in tmp.columns:\n",
    "        tmp[\"abs_err\"] = (tmp[y_true_col] - tmp[y_pred_col]).abs()\n",
    "    p = DIR_RES / f\"eval_rows_{TARGET}.csv\"\n",
    "    tmp.to_csv(p, index=False)\n",
    "    print(\"üíæ Guardado:\", p)\n",
    "\n",
    "if 'df_errors_rank' in globals() and df_errors_rank is not None:\n",
    "    p = DIR_RES / f\"errors_by_group_{TARGET}.csv\"\n",
    "    df_errors_rank.to_csv(p, index=False)\n",
    "    print(\"üíæ Guardado:\", p)\n",
    "\n",
    "print(\"\\n‚úÖ Listo. Este notebook est√° preparado para ejecutarse aun si faltan piezas; imprime advertencias claras.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68ce02",
   "metadata": {},
   "source": [
    "## 5) (Opcional) Evaluar **todos** los targets en lote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7a9015",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Puedes ejecutar esta celda para correr 3 evaluaciones r√°pidas y generar 3 JSONs en /results\n",
    "for tgt in [\"price\",\"consumption\",\"profit\"]:\n",
    "    TARGET = tgt\n",
    "    HOLDOUT_YEAR = None\n",
    "    print_header(f\"[Lote] Evaluando target={tgt}\")\n",
    "    # Para simplificar, re-ejecuta desde las celdas 5‚Üí10 manualmente si lo deseas.\n",
    "    print(\"Sugerencia: cambia arriba TARGET y vuelve a correr las celdas 5‚Üí10 en orden.\")\n",
    "print(\"Fin del modo lote.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}