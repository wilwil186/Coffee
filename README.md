# High Garden Coffee â€” Reto TÃ©cnico de ML (EDA, Modelado, EvaluaciÃ³n y Chatbot)

> Proyecto de analÃ­tica y machine learning para la empresa ficticia **High Garden Coffee**. 
> El objetivo es transformar datos histÃ³ricos (1990â€“2020) en **insights accionables**: tendencias de consumo, **rangos de precio** y **mÃ©tricas de rentabilidad** (ingresos, utilidad y margen). 
> Incluye una propuesta **BONUS** de Chatbot para consulta en lenguaje natural.

---

## ğŸ§­ Contexto del reto
Con base en el set de datos de consumo domÃ©stico de cafÃ© por **paÃ­s** y **tipo**, se busca:
- Analizar y documentar el dataset (EDA).
- Construir **modelos supervisados** por objetivo (`price`, `consumption`, `profit`) respetando la dimensiÃ³n temporal.
- Evaluar los modelos con mÃ©tricas transparentes y reproducibles.
- Presentar resultados de manera clara para negocio.
- (BONUS) Incluir un **chatbot** que responda preguntas del negocio usando las predicciones y KPIs.

> Este repositorio cubre los **requisitos mÃ­nimos** (AnÃ¡lisis, SoluciÃ³n, ImplementaciÃ³n/EvaluaciÃ³n y PresentaciÃ³n) y agrega el **BONUS**.

---

## ğŸ—‚ï¸ Estructura del repositorio

```
.
â”œâ”€â”€ EDA.ipynb                 # Limpieza, integraciÃ³n de precios y KPIs
â”œâ”€â”€ Inferencia.ipynb          # Modelado por objetivo (sin grÃ¡ficos)
â”œâ”€â”€ Evaluacion.ipynb          # Holdout, selecciÃ³n de artefactos y mÃ©tricas
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ io.py
â”‚   â””â”€â”€ metrics.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ coffee_clean.csv      # dataset maestro generado desde EDA
â”œâ”€â”€ models/                   # artefactos .joblib
â”œâ”€â”€ predicciones/             # CSVs de predicciones exportadas
â”œâ”€â”€ results/                  # figuras opcionales
â”œâ”€â”€ coffee_db.csv             # datos fuente
â”œâ”€â”€ precios.csv               # precios diarios (se anualizan en EDA)
â””â”€â”€ requirements.txt
```

---

## ğŸ“Š KPIs de negocio (definiciones reproducibles)

Estas columnas se calculan en **EDA** y quedan listas para modelado y reporting:

```python
# Asumiendo columnas: year, country, type, price, consumption
df = df.copy()

# 1) Ingresos
if {"price","consumption"} <= set(df.columns) and "revenue" not in df.columns:
    df["revenue"] = df["price"] * df["consumption"]

# 2) Utilidad (con costo unitario opcional)
COST_PER_UNIT = None  # Ajusta segÃºn tu negocio. Si None y existe 'profit', se respeta.
if "profit" not in df.columns:
    if COST_PER_UNIT is None:
        df["profit"] = df["revenue"]
    else:
        df["profit"] = df["revenue"] - COST_PER_UNIT * df["consumption"]

# 3) Margen
if "margin" not in df.columns and "revenue" in df.columns:
    df["margin"] = df["profit"] / df["revenue"]

# 4) ParticipaciÃ³n de mercado anual
if "market_share" not in df.columns and {"year","consumption"} <= set(df.columns):
    total_year = df.groupby("year")["consumption"].transform("sum")
    df["market_share"] = df["consumption"] / total_year
```

> **Sugerencia:** documenta el valor de `COST_PER_UNIT` usado en experimentos para interpretar correctamente `profit`.

---

## ğŸ§ª Modelado y evaluaciÃ³n

- **Targets:** `price`, `consumption`, `profit`.
- **Features base:** `year` (num), `country` y `type` (one-hot/ordinal). Evitar *leakage* (solo pasado).
- **ParticiÃ³n temporal:** `train/val/test` (holdout final: 2020).
- **Modelos:** baselines (Ãºltimo valor / promedio), Ridge, Lasso, RandomForest (puedes ampliar a GBMs).
- **MÃ©tricas:** `MAE`, `RMSE`, `sMAPE` y `RÂ²` cuando aplica.

**Ejemplo real (target=`price`, holdout=2020) de la Ãºltima ejecuciÃ³n:**  
`RMSE â‰ˆ 11.863`, `MAE â‰ˆ 7.893`, `sMAPE â‰ˆ 7.07%`, `n_val = 55`, artefacto: `lasso_price.joblib`.

> Nota: estos valores dependen de las *features* y de la particiÃ³n. MantÃ©n siempre la comparaciÃ³n con **baselines** para validar que el modelo agrega valor.

---

## ğŸš€ CÃ³mo reproducir

### 1) Entorno
```bash
python -m venv .venv
# Linux/Mac
source .venv/bin/activate
# Windows (PowerShell)
# .venv\Scripts\activate
pip install -r requirements.txt
```

### 2) Orden recomendado
1. **EDA.ipynb** â†’ genera `data/coffee_clean.csv` + KPIs.
2. **Inferencia.ipynb** â†’ entrena y guarda artefactos en `models/` (uno por target).
3. **Evaluacion.ipynb** â†’ imprime mÃ©tricas del holdout y selecciona el mejor artefacto. Puede producir CSVs en `predicciones/`.

### 3) Datos
- Coloca `coffee_db.csv` y `precios.csv` en el **raÃ­z** del repo (o ajusta rutas).

---

## ğŸ“’ â€œMÃ¡s bonitoâ€ en `Evaluacion.ipynb` (celdas listas para pegar)

> Estas celdas **no** agregan dependencias nuevas y se degradan con gracia si faltan variables/archivos.

### A) Resumen ejecutivo (robusto)
```python
from pathlib import Path
import json

def print_header(title):
    print("\n" + "â€”"*80)
    print(title.upper())
    print("â€”"*80)

def load_ev_if_any():
    # Intenta usar la variable `ev` del notebook; si no existe, busca un JSON en /results
    out = globals().get("ev", None)
    if out is not None:
        return out
    # fallback: results/ev_<TARGET>.json
    tgt = globals().get("TARGET", None)
    if tgt:
        p = Path("results") / f"ev_{tgt}.json"
        if p.exists():
            return json.loads(p.read_text(encoding="utf-8"))
    return None

print_header("Resumen ejecutivo de evaluaciÃ³n")
ev_local = load_ev_if_any()
if ev_local is None:
    print("No encontrÃ© `ev` ni results/ev_<TARGET>.json â€” ejecuta primero la celda principal de evaluaciÃ³n.")
else:
    print("Objetivo:", ev_local.get("target", globals().get("TARGET", "?")).upper())
    metrics = ev_local.get("metrics", {})
    for k, v in metrics.items():
        if isinstance(v, float):
            print(f"  {k:<10}: {v:,.4f}")
        else:
            print(f"  {k:<10}: {v}")
    best_art = ev_local.get("best_artifact") or ev_local.get("artifact") or "Â¿no registrado?"
    print("Mejor artefacto:", best_art)
```

### B) ComparaciÃ³n vs. baselines (si existe)
```python
print_header("ComparaciÃ³n vs baselines")
comp = ev_local.get("comparisons") if ev_local else None
if not comp:
    print("No hay tabla de comparaciÃ³n. (Opcional: guarda `ev['comparisons']`).")
else:
    import pandas as pd
    dfc = pd.DataFrame(comp).T
    display(dfc)
```

### C) Muestra de predicciones (auto-descubrimiento)
```python
print_header("Muestra de predicciones")
import pandas as pd

def try_load_predictions():
    # 1) predicciones/export
    tgt = globals().get("TARGET", None)
    if tgt:
        for name in [f"pred_{tgt}.csv", f"pred_{tgt}_holdout.csv"]:
            p = Path("predicciones") / name
            if p.exists():
                return pd.read_csv(p)
    # 2) results/preds_<TARGET>.csv
    if tgt:
        p2 = Path("results") / f"preds_{tgt}.csv"
        if p2.exists():
            return pd.read_csv(p2)
    return None

preds = try_load_predictions()
if preds is None:
    print("No encontrÃ© CSVs de predicciÃ³n. Genera y exporta desde tu pipeline de evaluaciÃ³n.")
else:
    # columnas amigables primero, si existen
    preferred = [c for c in ["year","country","type","y_true","y_pred","error","pred_price","pred_consumption","pred_profit"] if c in preds.columns]
    cols = preferred + [c for c in preds.columns if c not in preferred]
    display(preds[cols].head(10))
```

---

## ğŸ’¬ BONUS â€” Chatbot interno (prototipo)

Un **Streamlit** mÃ­nimo que responde preguntas de negocio (histÃ³rico y, si existen, predicciones) a partir de los CSVs del repo.

### EjecuciÃ³n rÃ¡pida
```bash
pip install streamlit pandas numpy
streamlit run app.py
```

### `app.py` (incluido en este repositorio como ejemplo)
- Carga `data/coffee_clean.csv` (o `coffee_db.csv` + `precios.csv` como respaldo).
- Si existen, integra CSVs de `predicciones/` (p. ej., `pred_price.csv`).
- Permite preguntas como: 
  - â€œ**Precio** en *Colombia* para **2020**â€
  - â€œ**Consumo** de *Brasil*, **2015â€“2020**â€
  - â€œ**Utilidad** por *tipo* en **2019**â€
- Devuelve tablas/resÃºmenes sin depender de un servicio externo.

> Â¿Quieres LLM? Puedes aÃ±adir `pip install openai` y crear una respuesta en lenguaje natural a partir de los resultados tabulares (dejamos el â€˜hookâ€™ en el cÃ³digo).

---

## ğŸ—ºï¸ Roadmap sugerido
- AÃ±adir **rezagos/MAs** y validaciÃ³n **walk-forward**.
- Probar **LightGBM/XGBoost** con *early stopping*.
- Registrar experimentos (MLflow) y **model cards** por artefacto.
- Extender el chatbot a **RAG** (Ã­ndice FAISS de KPIs/predicciones por paÃ­s/tipo/aÃ±o).

---

## ğŸ“ Licencia
Uso acadÃ©mico/demostrativo.
