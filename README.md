# High Garden Coffee â€” **PresentaciÃ³n de Resultados** (Reto TÃ©cnico ML)

> SoluciÃ³n de analÃ­tica y machine learning para la empresa **Garden Coffee**: EDA, modelado supervisado (consumo, precio, utilidad), evaluaciÃ³n rigurosa y demo en app. Este documento se centra en **presentar los resultados** del modelado y cÃ³mo reproducirlos.

---

## ğŸ¯ Objetivo del reto
Usar el histÃ³rico (1990â€“2020) de consumo (tazas), paÃ­ses y tipos de cafÃ© para:
- Analizar la informaciÃ³n y formular KPI de negocio (ingresos, costos, utilidad, margen).
- Construir y evaluar modelos que **predigan** consumo, precio y utilidad anual.
- Entregar **artefactos** de modelo y un flujo reproducible con una **demo** en app.

> Alineado a los mÃ­nimos de la prueba: anÃ¡lisis, soluciÃ³n analÃ­tica, implementaciÃ³n y evaluaciÃ³n, y **presentaciÃ³n de resultados** (ver PDF del reto).

---

## ğŸ§° Datos y alcance
- **`data/coffee_clean.csv`**: dataset anual por `country` y `type` con consumo (tazas) y precio anualizado.
- **Horizonte**: 1990â€“2020 (holdout = Ãºltimo aÃ±o disponible).
- **KPI de negocio** (calculados en EDA): ingresos (= precio Ã— consumo), costos (parametrizable), utilidad (= ingresos âˆ’ costos), margen, CAGR, participaciÃ³n por paÃ­s/tipo.

---

## ğŸ§ª MetodologÃ­a (resumen)
- **ParticiÃ³n temporal**: `train / val / test` con holdout del Ãºltimo aÃ±o, evitando leakage.
- **Features**: rezagos y medias mÃ³viles (solo pasado), codificaciÃ³n por paÃ­s y tipo.
- **Modelos**: baselines (Ãºltimo valor, promedio histÃ³rico) y modelos supervisados (Ridge, Lasso, **RandomForest**).
- **MÃ©tricas**: MAE, RMSE, **sMAPE** y n de observaciones por split.
- **Artefactos**: se guardan en `models/` como `.joblib` (uno por objetivo).

---

## ğŸ“ˆ Resultados de prueba (run actual)
Entrenamiento/evaluaciÃ³n realizado desde el notebook **`Inferencia_patched.ipynb`**. En validaciÃ³n, el mejor modelo para los tres objetivos fue **RandomForest**; abajo se reporta desempeÃ±o en **test** (n_test = 55).

### ğŸ”¹ `price` (precio anual)
- **Mejor modelo**: rf (validaciÃ³n MAE = 10.0550)
- **Test**: **RMSE = 0.8500**, **MAE = 0.8500**, **sMAPE = 0.383%**, **n_test = 55**
- **Artefacto**: `models/price_model.joblib`

### ğŸ”¹ `consumption` (tazas/aÃ±o)
- **Mejor modelo**: rf (validaciÃ³n MAE = 1,545,649.7304)
- **Test**: **RMSE = 5,270,065.0822**, **MAE = 2,021,107.0803**, **sMAPE = 1.547%**, **n_test = 55**
- **Artefacto**: `models/consumption_model.joblib`

### ğŸ”¹ `profit` (utilidad anual)
- **Mejor modelo**: rf (validaciÃ³n MAE = 819,023,721.3023)
- **Test**: **RMSE = 1,236,075,648.5734**, **MAE = 376,286,684.7858**, **sMAPE = 4.984%**, **n_test = 55**
- **Artefacto**: `models/profit_model.joblib`

> **Lectura ejecutiva**: Los sMAPE bajos (â‰²5%) en los tres objetivos indican **buen ajuste relativo** a la escala de cada variable. Para negocio, esto habilita estimaciones anuales de precio, consumo y utilidad con errores esperados acotados, Ãºtiles para planeaciÃ³n y escenarios por paÃ­s/tipo.

---

## ğŸ§ª ValidaciÃ³n y buenas prÃ¡cticas
- ComparaciÃ³n contra **baselines** (Ãºltimo valor y promedio histÃ³rico) para dimensionar la ganancia del modelo.
- **Holdout temporal** del aÃ±o mÃ¡s reciente y features 100% causales.
- Reporte de **n** por split y por segmento (paÃ­s/tipo) cuando aplique.
- Artefactos versionados y reproducibles con `requirements.txt` y notebooks.

---

## ğŸ” Reproducibilidad (paso a paso)
1) Crear entorno e instalar dependencias
```bash
python -m venv .venv && source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

2) EDA y KPIs (opcional si ya existe `data/coffee_clean.csv`)
- Ejecuta `EDA.ipynb` para limpiar, anualizar precios y exportar `data/coffee_clean.csv`.

3) Entrenar y evaluar
- Ejecuta `Inferencia_patched.ipynb` (o `Inferencia.ipynb`). Al finalizar se guardan:
  - `models/price_model.joblib`
  - `models/consumption_model.joblib`
  - `models/profit_model.joblib`
- Las predicciones de test/futuro se dejan en `predicciones/` y tablas en `results/` (si aplica).

4) Demo (app)
- Sigue **[guiaApp.md](./guiaApp.md)** para correr `app.py` (usa Google AI Studio API).

---

## ğŸ§© Uso de artefactos (snippet)
Para cargar un artefacto y predecir sobre nuevos datos con los mismos features:
```python
from joblib import load
import pandas as pd

art = load("models/price_model.joblib")
model = art["model"]
y_col = art.get("y_col", "price")
feat_cols = art["feat_cols"]

# df_new debe tener las mismas columnas de features
X_new = df_new[feat_cols].dropna()
df_pred = df_new.loc[X_new.index, ["year","country","type"]].copy()
yhat = model.predict(X_new)
df_pred[f"pred_{y_col}"] = yhat
```

---

## ğŸ’¬ BONUS â€” Copiloto con LLM
Se incluye `app.py`, un **chatbot** que permite consultar mÃ©tricas y predicciones de forma natural (por ejemplo: â€œproyecciÃ³n de precio para Colombia 2021â€“2023â€). La guÃ­a de uso estÃ¡ en **[guiaApp.md](./guiaApp.md)** (API de Google AI Studio).

---

## âš ï¸ Limitaciones y prÃ³ximos pasos
- Mejorar imputaciÃ³n/outliers antes de features.
- Probar LightGBM/XGBoost y Prophet por segmento paÃ­sÃ—tipo.
- Intervalos de predicciÃ³n basados en varianza de residuales por segmento.
- MLOps: `dvc` para versionar datos/modelos y CI para validar notebooks.

---

## ğŸ“‚ Estructura relevante
```
.
â”œâ”€â”€ EDA.ipynb
â”œâ”€â”€ Inferencia.ipynb
â”œâ”€â”€ Inferencia_patched.ipynb
â”œâ”€â”€ app.py
â”œâ”€â”€ guiaApp.md
â”œâ”€â”€ data/coffee_clean.csv
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ price_model.joblib
â”‚   â”œâ”€â”€ consumption_model.joblib
â”‚   â””â”€â”€ profit_model.joblib
â”œâ”€â”€ predicciones/
â””â”€â”€ results/
```

---

## ğŸ“ Licencia
Este proyecto se publica bajo **GNU GPL v3**. Si vas a reutilizar cÃ³digo o modelos, mantÃ©n el aviso de licencia y comparte mejoras bajo los mismos tÃ©rminos.
