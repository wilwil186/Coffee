{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d6828f6e",
      "metadata": {},
      "source": [
        "# Inferencia - High Garden Coffee\n",
        "Este notebook contiene únicamente la parte **inferencial**:\n",
        "- Modelado supervisado\n",
        "- Validación temporal\n",
        "- Métricas de evaluación\n",
        "- Intervalos de predicción\n",
        "\n",
        "👉 No hay gráficas (quedan en el EDA).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f8941a2",
      "metadata": {},
      "source": [
        "## 1. Imports y configuración"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "06b185dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Dict\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import RidgeCV, LassoCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# XGBoost opcional\n",
        "try:\n",
        "    from xgboost import XGBRegressor\n",
        "    XGB_AVAILABLE = True\n",
        "except Exception:\n",
        "    XGB_AVAILABLE = False\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 120)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3323afc1",
      "metadata": {},
      "source": [
        "## 2. Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07393a01",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "country",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "coffee_type",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "1990_91",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "1991_92",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "1992_93",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "1993_94",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "1994_95",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "1995_96",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "1996_97",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "1997_98",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "1998_99",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "1999_00",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "2000_01",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "2001_02",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "2002_03",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "2003_04",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "2004_05",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "2005_06",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "2006_07",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "2007_08",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "2008_09",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "2009_10",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "2010_11",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "2011_12",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "2012_13",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "2013_14",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "2014_15",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "2015_16",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "2016_17",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "2017_18",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "2018_19",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "2019_20",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "total_domestic_consumption",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "ref": "f5011345-bcb8-47e9-8f19-4500df27c9d1",
              "rows": [
                [
                  "0",
                  "Angola",
                  "Robusta/Arabica",
                  "1200000",
                  "1800000",
                  "2100000",
                  "1200000",
                  "1500000",
                  "600000",
                  "1200000",
                  "2400000",
                  "1800000",
                  "1200000",
                  "1200000",
                  "1200000",
                  "1200000",
                  "900000",
                  "900000",
                  "900000",
                  "1800000",
                  "1800000",
                  "1800000",
                  "1800000",
                  "1800000",
                  "1800000",
                  "1800000",
                  "1800000",
                  "1800000",
                  "1800000",
                  "1800000",
                  "1800000",
                  "1800000",
                  "1800000",
                  "46500000"
                ],
                [
                  "1",
                  "Bolivia (Plurinational State of)",
                  "Arabica",
                  "1500000",
                  "1620000",
                  "1650000",
                  "1710000",
                  "1770000",
                  "1830000",
                  "1890000",
                  "1950000",
                  "1980000",
                  "2040000",
                  "2100000",
                  "2190000",
                  "2250000",
                  "2310000",
                  "2700000",
                  "2460000",
                  "2520000",
                  "2610000",
                  "2700000",
                  "2760000",
                  "2850000",
                  "2940000",
                  "3030000",
                  "3120000",
                  "3210000",
                  "3300000",
                  "3420000",
                  "3510000",
                  "3600000",
                  "3660000",
                  "75180000"
                ],
                [
                  "2",
                  "Brazil",
                  "Arabica/Robusta",
                  "492000000",
                  "510000000",
                  "534000000",
                  "546000000",
                  "558000000",
                  "606000000",
                  "660000000",
                  "690000000",
                  "732000000",
                  "762000000",
                  "792000000",
                  "815400000",
                  "825000000",
                  "852000000",
                  "896760000",
                  "932280000",
                  "979860000",
                  "1026600000",
                  "1059600000",
                  "1103400000",
                  "1147920000",
                  "1183200000",
                  "1219800000",
                  "1205100000",
                  "1219980000",
                  "1230480000",
                  "1273500000",
                  "1319820000",
                  "1332000000",
                  "1320000000",
                  "27824700000"
                ]
              ],
              "shape": {
                "columns": 33,
                "rows": 3
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "      <th>coffee_type</th>\n",
              "      <th>1990_91</th>\n",
              "      <th>1991_92</th>\n",
              "      <th>1992_93</th>\n",
              "      <th>1993_94</th>\n",
              "      <th>1994_95</th>\n",
              "      <th>1995_96</th>\n",
              "      <th>1996_97</th>\n",
              "      <th>1997_98</th>\n",
              "      <th>1998_99</th>\n",
              "      <th>1999_00</th>\n",
              "      <th>2000_01</th>\n",
              "      <th>2001_02</th>\n",
              "      <th>2002_03</th>\n",
              "      <th>2003_04</th>\n",
              "      <th>2004_05</th>\n",
              "      <th>2005_06</th>\n",
              "      <th>2006_07</th>\n",
              "      <th>2007_08</th>\n",
              "      <th>2008_09</th>\n",
              "      <th>2009_10</th>\n",
              "      <th>2010_11</th>\n",
              "      <th>2011_12</th>\n",
              "      <th>2012_13</th>\n",
              "      <th>2013_14</th>\n",
              "      <th>2014_15</th>\n",
              "      <th>2015_16</th>\n",
              "      <th>2016_17</th>\n",
              "      <th>2017_18</th>\n",
              "      <th>2018_19</th>\n",
              "      <th>2019_20</th>\n",
              "      <th>total_domestic_consumption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Angola</td>\n",
              "      <td>Robusta/Arabica</td>\n",
              "      <td>1200000</td>\n",
              "      <td>1800000</td>\n",
              "      <td>2100000</td>\n",
              "      <td>1200000</td>\n",
              "      <td>1500000</td>\n",
              "      <td>600000</td>\n",
              "      <td>1200000</td>\n",
              "      <td>2400000</td>\n",
              "      <td>1800000</td>\n",
              "      <td>1200000</td>\n",
              "      <td>1200000</td>\n",
              "      <td>1200000</td>\n",
              "      <td>1200000</td>\n",
              "      <td>900000</td>\n",
              "      <td>900000</td>\n",
              "      <td>900000</td>\n",
              "      <td>1800000</td>\n",
              "      <td>1800000</td>\n",
              "      <td>1800000</td>\n",
              "      <td>1800000</td>\n",
              "      <td>1800000</td>\n",
              "      <td>1800000</td>\n",
              "      <td>1800000</td>\n",
              "      <td>1800000</td>\n",
              "      <td>1800000</td>\n",
              "      <td>1800000</td>\n",
              "      <td>1800000</td>\n",
              "      <td>1800000</td>\n",
              "      <td>1800000</td>\n",
              "      <td>1800000</td>\n",
              "      <td>46500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bolivia (Plurinational State of)</td>\n",
              "      <td>Arabica</td>\n",
              "      <td>1500000</td>\n",
              "      <td>1620000</td>\n",
              "      <td>1650000</td>\n",
              "      <td>1710000</td>\n",
              "      <td>1770000</td>\n",
              "      <td>1830000</td>\n",
              "      <td>1890000</td>\n",
              "      <td>1950000</td>\n",
              "      <td>1980000</td>\n",
              "      <td>2040000</td>\n",
              "      <td>2100000</td>\n",
              "      <td>2190000</td>\n",
              "      <td>2250000</td>\n",
              "      <td>2310000</td>\n",
              "      <td>2700000</td>\n",
              "      <td>2460000</td>\n",
              "      <td>2520000</td>\n",
              "      <td>2610000</td>\n",
              "      <td>2700000</td>\n",
              "      <td>2760000</td>\n",
              "      <td>2850000</td>\n",
              "      <td>2940000</td>\n",
              "      <td>3030000</td>\n",
              "      <td>3120000</td>\n",
              "      <td>3210000</td>\n",
              "      <td>3300000</td>\n",
              "      <td>3420000</td>\n",
              "      <td>3510000</td>\n",
              "      <td>3600000</td>\n",
              "      <td>3660000</td>\n",
              "      <td>75180000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Brazil</td>\n",
              "      <td>Arabica/Robusta</td>\n",
              "      <td>492000000</td>\n",
              "      <td>510000000</td>\n",
              "      <td>534000000</td>\n",
              "      <td>546000000</td>\n",
              "      <td>558000000</td>\n",
              "      <td>606000000</td>\n",
              "      <td>660000000</td>\n",
              "      <td>690000000</td>\n",
              "      <td>732000000</td>\n",
              "      <td>762000000</td>\n",
              "      <td>792000000</td>\n",
              "      <td>815400000</td>\n",
              "      <td>825000000</td>\n",
              "      <td>852000000</td>\n",
              "      <td>896760000</td>\n",
              "      <td>932280000</td>\n",
              "      <td>979860000</td>\n",
              "      <td>1026600000</td>\n",
              "      <td>1059600000</td>\n",
              "      <td>1103400000</td>\n",
              "      <td>1147920000</td>\n",
              "      <td>1183200000</td>\n",
              "      <td>1219800000</td>\n",
              "      <td>1205100000</td>\n",
              "      <td>1219980000</td>\n",
              "      <td>1230480000</td>\n",
              "      <td>1273500000</td>\n",
              "      <td>1319820000</td>\n",
              "      <td>1332000000</td>\n",
              "      <td>1320000000</td>\n",
              "      <td>27824700000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            country      coffee_type    1990_91    1991_92  \\\n",
              "0                            Angola  Robusta/Arabica    1200000    1800000   \n",
              "1  Bolivia (Plurinational State of)          Arabica    1500000    1620000   \n",
              "2                            Brazil  Arabica/Robusta  492000000  510000000   \n",
              "\n",
              "     1992_93    1993_94    1994_95    1995_96    1996_97    1997_98  \\\n",
              "0    2100000    1200000    1500000     600000    1200000    2400000   \n",
              "1    1650000    1710000    1770000    1830000    1890000    1950000   \n",
              "2  534000000  546000000  558000000  606000000  660000000  690000000   \n",
              "\n",
              "     1998_99    1999_00    2000_01    2001_02    2002_03    2003_04  \\\n",
              "0    1800000    1200000    1200000    1200000    1200000     900000   \n",
              "1    1980000    2040000    2100000    2190000    2250000    2310000   \n",
              "2  732000000  762000000  792000000  815400000  825000000  852000000   \n",
              "\n",
              "     2004_05    2005_06    2006_07     2007_08     2008_09     2009_10  \\\n",
              "0     900000     900000    1800000     1800000     1800000     1800000   \n",
              "1    2700000    2460000    2520000     2610000     2700000     2760000   \n",
              "2  896760000  932280000  979860000  1026600000  1059600000  1103400000   \n",
              "\n",
              "      2010_11     2011_12     2012_13     2013_14     2014_15     2015_16  \\\n",
              "0     1800000     1800000     1800000     1800000     1800000     1800000   \n",
              "1     2850000     2940000     3030000     3120000     3210000     3300000   \n",
              "2  1147920000  1183200000  1219800000  1205100000  1219980000  1230480000   \n",
              "\n",
              "      2016_17     2017_18     2018_19     2019_20  total_domestic_consumption  \n",
              "0     1800000     1800000     1800000     1800000                    46500000  \n",
              "1     3420000     3510000     3600000     3660000                    75180000  \n",
              "2  1273500000  1319820000  1332000000  1320000000                 27824700000  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "PATH_COFFEE = \"coffee_db.csv\"\n",
        "PATH_PRICES = \"precios.csv\"ss\n",
        "\n",
        "def _try_read(path: str) -> pd.DataFrame:\n",
        "    if os.path.exists(path):\n",
        "        return pd.read_csv(path)\n",
        "    alt = os.path.join(\"/mnt/data\", os.path.basename(path))\n",
        "    if os.path.exists(alt):\n",
        "        return pd.read_csv(alt)\n",
        "    raise FileNotFoundError(f\"No encontré {path} (ni {alt}).\")\n",
        "\n",
        "def _norm_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    df.columns = (\n",
        "        df.columns.str.lower()\n",
        "        .str.replace(\"á\",\"a\").str.replace(\"é\",\"e\").str.replace(\"í\",\"i\").str.replace(\"ó\",\"o\").str.replace(\"ú\",\"u\").str.replace(\"ñ\",\"n\")\n",
        "        .str.replace(r\"[^a-z0-9]+\", \"_\", regex=True)\n",
        "        .str.strip(\"_\")\n",
        "    )\n",
        "    return df\n",
        "\n",
        "coffee = _norm_cols(_try_read(PATH_COFFEE))\n",
        "\n",
        "# precios externo (opcional)\n",
        "prices_ext = None\n",
        "try:\n",
        "    prices_ext = _norm_cols(_try_read(PATH_PRICES))\n",
        "except FileNotFoundError:\n",
        "    pass\n",
        "\n",
        "coffee.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "525530f3",
      "metadata": {},
      "source": [
        "## 3. Detección de columnas y objetivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f84a53ef",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['country', 'coffee_type', '1990_91', '1991_92', '1992_93', '1993_94', '1994_95', '1995_96', '1996_97', '1997_98', '1998_99', '1999_00', '2000_01', '2001_02', '2002_03', '2003_04', '2004_05', '2005_06', '2006_07', '2007_08', '2008_09', '2009_10', '2010_11', '2011_12', '2012_13', '2013_14', '2014_15', '2015_16', '2016_17', '2017_18', '2018_19', '2019_20', 'total_domestic_consumption']\n"
          ]
        }
      ],
      "source": [
        "print(coffee.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bec52f15",
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "No pude detectar la columna de año.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m col: targets[k] = col\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m year_col:\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo pude detectar la columna de año.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m country_col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m coffee.columns:\n\u001b[32m     36\u001b[39m     coffee[country_col] = \u001b[33m\"\u001b[39m\u001b[33mALL\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[31mValueError\u001b[39m: No pude detectar la columna de año."
          ]
        }
      ],
      "source": [
        "\n",
        "YEAR_CANDIDATES = [\"year\", \"anio\", \"ano\"]\n",
        "COUNTRY_CANDIDATES = [\"country\", \"pais\"]\n",
        "TYPE_CANDIDATES = [\"type\", \"tipo\", \"variety\", \"categoria\"]\n",
        "\n",
        "TARGET_ALIASES = {\n",
        "    \"consumption\": [\"consumption\", \"consumo\"],\n",
        "    \"price\": [\"price\", \"precio\"],\n",
        "    \"profit\": [\"profit\", \"utilidad\", \"ganancia\"]\n",
        "}\n",
        "\n",
        "def find_col(df, candidates):\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "year_col = find_col(coffee, YEAR_CANDIDATES)\n",
        "country_col = find_col(coffee, COUNTRY_CANDIDATES) or \"country\"\n",
        "type_col = find_col(coffee, TYPE_CANDIDATES)\n",
        "\n",
        "def find_target(df, names):\n",
        "    for n in names:\n",
        "        if n in df.columns:\n",
        "            return n\n",
        "    return None\n",
        "\n",
        "targets = {}\n",
        "for k, aliases in TARGET_ALIASES.items():\n",
        "    col = find_target(coffee, aliases)\n",
        "    if col: targets[k] = col\n",
        "\n",
        "if not year_col:\n",
        "    raise ValueError(\"No pude detectar la columna de año.\")\n",
        "\n",
        "if country_col not in coffee.columns:\n",
        "    coffee[country_col] = \"ALL\"\n",
        "if type_col and type_col not in coffee.columns:\n",
        "    type_col = None\n",
        "\n",
        "print(\"year_col:\", year_col, \"| country_col:\", country_col, \"| type_col:\", type_col)\n",
        "print(\"targets detectados:\", targets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aca41531",
      "metadata": {},
      "source": [
        "## 4. Merge con precios externos (opcional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8383b979",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def safe_merge_externals(df: pd.DataFrame, ext: pd.DataFrame) -> pd.DataFrame:\n",
        "    if ext is None:\n",
        "        return df\n",
        "    keys = [k for k in [year_col, country_col] if k in ext.columns]\n",
        "    if not keys:\n",
        "        keys = [year_col] if year_col in ext.columns else []\n",
        "    if not keys:\n",
        "        return df\n",
        "    rename_map = {c: f\"ext_{c}\" for c in ext.columns if c not in keys}\n",
        "    ext2 = ext.rename(columns=rename_map)\n",
        "    merged = df.merge(ext2, on=keys, how=\"left\")\n",
        "    return merged\n",
        "\n",
        "data = safe_merge_externals(coffee, prices_ext)\n",
        "data[year_col] = pd.to_numeric(data[year_col], errors=\"coerce\").astype(\"Int64\")\n",
        "data = data.sort_values([year_col, country_col] + ([type_col] if type_col else []))\n",
        "data.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a5d9a11",
      "metadata": {},
      "source": [
        "## 5. Splits temporales por año"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfc486e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def year_based_cv(df, year_col, initial_train_years=20, val_years=2, step=1):\n",
        "    years = sorted([int(y) for y in df[year_col].dropna().unique()])\n",
        "    if len(years) < (initial_train_years + val_years):\n",
        "        initial_train_years = max(3, len(years) - val_years - 1)\n",
        "    for start in range(0, max(1, len(years) - initial_train_years - val_years + 1), step):\n",
        "        train_years = years[:initial_train_years + start]\n",
        "        val_years_ = years[initial_train_years + start: initial_train_years + start + val_years]\n",
        "        tr_idx = df.index[df[year_col].isin(train_years)]\n",
        "        va_idx = df.index[df[year_col].isin(val_years_)]\n",
        "        yield tr_idx, va_idx, train_years, val_years_\n",
        "\n",
        "CV_GENERATOR = list(year_based_cv(data, year_col, initial_train_years=21, val_years=3, step=1))\n",
        "len(CV_GENERATOR), CV_GENERATOR[0][2][-1:], CV_GENERATOR[0][3]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c30355c3",
      "metadata": {},
      "source": [
        "## 6. Features con lags y rolling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b96d822e",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "NUMERIC_EXCLUDE = set([year_col])\n",
        "TARGET_SET = set(targets.values())\n",
        "CAT_COLS = [c for c in [country_col, type_col] if c is not None]\n",
        "\n",
        "def add_group_safe_lags(df: pd.DataFrame, group_cols: List[str], lag_cols: List[str], lags=(1,2), add_roll=True):\n",
        "    df = df.copy()\n",
        "    sort_cols = [year_col] + group_cols\n",
        "    df = df.sort_values(sort_cols)\n",
        "    for col in lag_cols:\n",
        "        base = df.groupby(group_cols, group_keys=False)[col]\n",
        "        for L in lags:\n",
        "            df[f\"{col}_lag{L}\"] = base.shift(L)\n",
        "        if add_roll:\n",
        "            s = base.shift(1)\n",
        "            for win in [2,3,5]:\n",
        "                df[f\"{col}_ma{win}\"] = s.rolling(win, min_periods=1).mean()\n",
        "                df[f\"{col}_std{win}\"] = s.rolling(win, min_periods=2).std()\n",
        "    return df\n",
        "\n",
        "def build_xy(df: pd.DataFrame, y_col: str) -> Tuple[pd.DataFrame, pd.Series, List[str], List[str]]:\n",
        "    numeric_cols = [c for c in df.select_dtypes(include=[np.number]).columns \n",
        "                    if c not in TARGET_SET and c != year_col]\n",
        "    lag_pool = sorted(set(numeric_cols + [y_col]))\n",
        "    df_feat = add_group_safe_lags(df, CAT_COLS, lag_pool, lags=(1,2), add_roll=True)\n",
        "    feat_cols = [c for c in df_feat.columns if any(s in c for s in [\"_lag\", \"_ma\", \"_std\"])]\n",
        "    df_feat[\"t_index\"] = df_feat.groupby(CAT_COLS).cumcount()\n",
        "    feat_cols += [\"t_index\"]\n",
        "    X = df_feat[feat_cols + CAT_COLS]\n",
        "    y = df_feat[y_col]\n",
        "    return X, y, feat_cols, CAT_COLS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3719ecb",
      "metadata": {},
      "source": [
        "## 7. Métricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c79a40dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def rmse(y_true, y_pred): \n",
        "    return float(np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2)))\n",
        "\n",
        "def smape(y_true, y_pred):\n",
        "    y_true = np.array(y_true, dtype=float)\n",
        "    y_pred = np.array(y_pred, dtype=float)\n",
        "    denom = (np.abs(y_true) + np.abs(y_pred))\n",
        "    denom = np.where(denom == 0, 1e-9, denom)\n",
        "    return float(np.mean(2.0 * np.abs(y_pred - y_true) / denom) * 100)\n",
        "\n",
        "def mdape(y_true, y_pred):\n",
        "    y_true = np.array(y_true, dtype=float)\n",
        "    y_pred = np.array(y_pred, dtype=float)\n",
        "    denom = np.where(y_true == 0, 1e-9, np.abs(y_true))\n",
        "    return float(np.median(np.abs((y_true - y_pred) / denom)) * 100)\n",
        "\n",
        "def mase(y_true, y_pred, y_train, m=1):\n",
        "    y_true, y_pred = np.array(y_true, dtype=float), np.array(y_pred, dtype=float)\n",
        "    y_train = np.array(y_train, dtype=float)\n",
        "    if len(y_train) <= m:\n",
        "        return np.nan\n",
        "    denom = np.mean(np.abs(y_train[m:] - y_train[:-m]))\n",
        "    denom = denom if denom != 0 else 1e-9\n",
        "    return float(np.mean(np.abs(y_true - y_pred)) / denom)\n",
        "\n",
        "def metrics_dict(y_true, y_pred, y_train_for_mase):\n",
        "    return {\n",
        "        \"RMSE\": rmse(y_true, y_pred),\n",
        "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
        "        \"sMAPE(%)\": smape(y_true, y_pred),\n",
        "        \"MdAPE(%)\": mdape(y_true, y_pred),\n",
        "        \"MASE\": mase(y_true, y_pred, y_train_for_mase, m=1)\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae97d985",
      "metadata": {},
      "source": [
        "## 8. Baselines Naive y SNaive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec14c70f",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def baseline_naive(train_df, val_df, y_col):\n",
        "    tr = train_df.sort_values([year_col, *CAT_COLS])\n",
        "    va = val_df.sort_values([year_col, *CAT_COLS])\n",
        "    last_train = tr.groupby(CAT_COLS)[y_col].last().to_dict()\n",
        "    preds = []\n",
        "    for _, row in va.iterrows():\n",
        "        key = tuple(row[c] for c in CAT_COLS)\n",
        "        preds.append(last_train.get(key, tr[y_col].mean()))\n",
        "    return np.array(preds)\n",
        "\n",
        "def baseline_snaive(train_df, val_df, y_col, season_m=1):\n",
        "    if season_m == 1:\n",
        "        return baseline_naive(train_df, val_df, y_col)\n",
        "    return baseline_naive(train_df, val_df, y_col)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56541e27",
      "metadata": {},
      "source": [
        "## 9. Modelos supervisados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5b6f5c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def make_preprocessor(cat_cols: List[str], scale_numeric: bool):\n",
        "    transformers = []\n",
        "    if cat_cols:\n",
        "        transformers.append((\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols))\n",
        "    if scale_numeric:\n",
        "        pre = ColumnTransformer(transformers, remainder=\"passthrough\")\n",
        "        return Pipeline([(\"ct\", pre), (\"scaler\", StandardScaler(with_mean=False))])\n",
        "    else:\n",
        "        return ColumnTransformer(transformers, remainder=\"passthrough\")\n",
        "\n",
        "def model_registry():\n",
        "    models = {\n",
        "        \"ridge\": Pipeline([\n",
        "            (\"pre\", make_preprocessor(CAT_COLS, scale_numeric=True)),\n",
        "            (\"mdl\", RidgeCV(alphas=np.logspace(-3, 3, 15), cv=5))\n",
        "        ]),\n",
        "        \"lasso\": Pipeline([\n",
        "            (\"pre\", make_preprocessor(CAT_COLS, scale_numeric=True)),\n",
        "            (\"mdl\", LassoCV(alphas=np.logspace(-3, 1, 15), cv=5, random_state=42, n_jobs=-1, max_iter=5000))\n",
        "        ]),\n",
        "        \"rf\": Pipeline([\n",
        "            (\"pre\", make_preprocessor(CAT_COLS, scale_numeric=False)),\n",
        "            (\"mdl\", RandomForestRegressor(\n",
        "                n_estimators=400, max_depth=None, min_samples_leaf=2, random_state=42, n_jobs=-1\n",
        "            ))\n",
        "        ]),\n",
        "    }\n",
        "    if XGB_AVAILABLE:\n",
        "        models[\"xgb\"] = Pipeline([\n",
        "            (\"pre\", make_preprocessor(CAT_COLS, scale_numeric=False)),\n",
        "            (\"mdl\", XGBRegressor(\n",
        "                n_estimators=800, learning_rate=0.05, max_depth=6, subsample=0.8, colsample_bytree=0.8,\n",
        "                random_state=42, tree_method=\"hist\", n_jobs=-1\n",
        "            ))\n",
        "        ])\n",
        "    return models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9efd7401",
      "metadata": {},
      "source": [
        "## 10. Validación cruzada temporal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "504984f0",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def eval_one_target(df: pd.DataFrame, y_col: str) -> pd.DataFrame:\n",
        "    X_all, y_all, feat_cols, cat_cols = build_xy(df, y_col)\n",
        "    models = model_registry()\n",
        "    rows = []\n",
        "    X_all = X_all.copy()\n",
        "    X_all.index = df.index\n",
        "    y_all = y_all.loc[X_all.index]\n",
        "    y_train_global = y_all.dropna()\n",
        "    for fold_id, (tr_idx, va_idx, tr_years, va_years) in enumerate(CV_GENERATOR, start=1):\n",
        "        X_tr = X_all.loc[tr_idx].dropna()\n",
        "        y_tr = y_all.loc[X_tr.index]\n",
        "        X_va = X_all.loc[va_idx].dropna()\n",
        "        y_va = y_all.loc[X_va.index]\n",
        "        train_df = df.loc[X_tr.index]\n",
        "        val_df   = df.loc[X_va.index]\n",
        "        yhat_naive  = baseline_naive(train_df, val_df, y_col)\n",
        "        yhat_snaive = baseline_snaive(train_df, val_df, y_col)\n",
        "        rows.append({\"target\": y_col, \"model\": \"naive\", \"fold\": fold_id,\n",
        "                     **metrics_dict(y_va.values, yhat_naive, y_tr.values)})\n",
        "        rows.append({\"target\": y_col, \"model\": \"snaive\", \"fold\": fold_id,\n",
        "                     **metrics_dict(y_va.values, yhat_snaive, y_tr.values)})\n",
        "        for name, pipe in models.items():\n",
        "            mdl = clone(pipe)\n",
        "            mdl.fit(X_tr, y_tr)\n",
        "            pred = mdl.predict(X_va)\n",
        "            rows.append({\"target\": y_col, \"model\": name, \"fold\": fold_id,\n",
        "                         **metrics_dict(y_va.values, pred, y_tr.values)})\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "all_results = []\n",
        "for logical_name, y_col in targets.items():\n",
        "    print(f\"↳ Evaluando: {logical_name} [{y_col}]\")\n",
        "    res = eval_one_target(data, y_col)\n",
        "    res[\"logical_target\"] = logical_name\n",
        "    all_results.append(res)\n",
        "\n",
        "results_df = pd.concat(all_results, ignore_index=True)\n",
        "results_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31e2e568",
      "metadata": {},
      "source": [
        "## 11. Resumen de métricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "971f8868",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def summarize_results(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    agg = df.groupby([\"logical_target\", \"model\"]).agg(\n",
        "        RMSE_mean=(\"RMSE\",\"mean\"), MAE_mean=(\"MAE\",\"mean\"),\n",
        "        sMAPE_mean=(\"sMAPE(%)\",\"mean\"), MdAPE_mean=(\"MdAPE(%)\",\"mean\"),\n",
        "        MASE_mean=(\"MASE\",\"mean\"), folds=(\"fold\",\"nunique\")\n",
        "    ).reset_index()\n",
        "    agg[\"rank_sMAPE\"] = agg.groupby(\"logical_target\")[\"sMAPE_mean\"].rank(method=\"first\")\n",
        "    return agg.sort_values([\"logical_target\",\"rank_sMAPE\"])\n",
        "\n",
        "summary_df = summarize_results(results_df)\n",
        "summary_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73c277ab",
      "metadata": {},
      "source": [
        "## 12. Entrenamiento final y guardado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f0149cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from joblib import dump\n",
        "import pathlib\n",
        "\n",
        "MODELS_OUT = pathlib.Path(\"models\"); MODELS_OUT.mkdir(exist_ok=True)\n",
        "\n",
        "BEST_BY_TARGET = (\n",
        "    summary_df.loc[~summary_df[\"model\"].isin([\"naive\",\"snaive\"])]\n",
        "    .sort_values([\"logical_target\",\"sMAPE_mean\"])\n",
        "    .groupby(\"logical_target\").first().reset_index()\n",
        ")[[\"logical_target\",\"model\"]]\n",
        "\n",
        "print(BEST_BY_TARGET)\n",
        "\n",
        "final_artifacts = []\n",
        "for _, row in BEST_BY_TARGET.iterrows():\n",
        "    logical_target = row[\"logical_target\"]\n",
        "    y_col = targets[logical_target]\n",
        "    X_all, y_all, feat_cols, cat_cols = build_xy(data, y_col)\n",
        "    X_fit = X_all.dropna(); y_fit = y_all.loc[X_fit.index]\n",
        "    mdl = clone(model_registry()[row[\"model\"]])\n",
        "    mdl.fit(X_fit, y_fit)\n",
        "    path_m = MODELS_OUT / f\"{logical_target}_{row['model']}.joblib\"\n",
        "    dump(mdl, path_m)\n",
        "    final_artifacts.append((logical_target, row[\"model\"], str(path_m)))\n",
        "\n",
        "pd.DataFrame(final_artifacts, columns=[\"target\",\"model\",\"path\"])\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
